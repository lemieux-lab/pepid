[performance]
python = python # path to python/pypy/etc. executable
extra args =

[logging]
level = info # Valid values are debug, info, warning, error, fatal.

[data]
output = pepid_res_yeast.tsv # where to save the results
queries = batched_yeast.mgf # input query mgf
database = yeast.fasta # input database
workdir = /tmp/pepidrun_yeast/
tmpdir = /tmp/ # where to put temporary files

[processing.query]
enabled = true
workers = 56
postprocessing function = extensions.stub
postprocessing workers = 32
batch size = 4640 # batch size for parallel processing
max peaks = 9999 # Discard spectra with more than this many peaks
min peaks = 0 # Discard spectra with fewer than this many peaks
min mass = 300
max mass = 6000
max charge = 6 # Max charge for spectra
min charge = 2 # Min charge for spectra

[processing.db]
enabled = true
workers = 8
postprocessing workers = 32
protein processing function = db.process_entry
decoy protein processing function = db.process_entry_decoy
postprocessing function = db.stub
batch size = 1180
variable modifications = M+15.994915 # Comma-separated mod list (default: M(ox))
fixed modifications = C+57.0215 # Comma-separated mod list (default: CAM)
nterm cleavage = 1.007825
cterm cleavage = 17.002735
max variable modifications = 3
# Digestion rule as a regular expression
digestion = ([RK](?!P))|((?<=W)K(?=P))|((?<=M)R(?=P)) # Trypsin: expasy rule
#digestion = ([RK](?!P)) # Simplified trypsin (like Comet)
max missed cleavages = 2
# required digested peptide properties for inclusion below
min length = 6
max length = 50
min mass = 300
max mass = 6000
max charge = 5 # Max charge to generate candidates
spectrum function = db.theoretical_spectrum # function to use to generate spectra for candidates
rt function = db.pred_rt # function to use for retention time prediction
generate decoys = true
decoy prefix = DECOY_
decoy method = reverse # possible choices are reverse or shuffle
decoy type = protein # either peptide or protein

[processing.db.theoretical_spectrum]
exclude last aa = true
# Weights indicates the theoretical spectrum "intensity" output for each AA and series.
# The format is {"some series": {"AA": weight, ..., "series": weight}, ...}
# where "some series" is a series label such as "b" or "y", "series" is the literal word "series" and indicates
# a special weight multiplying the entire series' intensities,
# "AA" is an amino acid such as "P", and weight is a float such as 0.5.
# Missing values are considered to be 1.0
# Example:
# {"y": {"P": 5.0}, "b": {"D": 5.0, "N": 2.0, "V": 3.0, "E": 3.0, "Q": 2.0, "I": 3.0, "L": 3.0}} # x!tandem "synthesis"
# An empty dict is {}, not the empty string.
#weights = {"y": {"P": 5.0}, "b": {"D": 5.0, "N": 2.0, "V": 3.0, "E": 3.0, "Q": 2.0, "I": 3.0, "L": 3.0}} # x!tandem "synthesis"
weights = {"y": {"P": 5.0}, "b": {"D": 5.0, "N": 2.0, "V": 3.0, "E": 3.0, "Q": 2.0, "I": 3.0, "L": 3.0}}

[postprocessing]
enabled = true
db = true
queries = true

# -> search.scoring
[scoring]
enabled = true
workers = 64
batch size = 6500
sharding threshold = 1000000 # create a new shard after X results stored in this shard
candidate filtering tolerance = -100,100 # left and right side tolerance for candidate filtering previous to search
filtering unit = ppm
function = search.xcorr_hyperscore
#function = search.cosine

[scoring.xcorr]
bin resolution = 150 # mass error tolerance for matching peaks
bin matching unit = ppm # ppm or abs (any non-ppm value assumed to be abs)
correlation window size = 75 # window size for averaging step in correlation
norm window count = 10 # how many windows to use for intensity normalization
intensity cutoff = 0.05 # ignore peaks with intensity less than this times max intensity
match multiplier = 1 # intensity is regularized by the max and then multiplied by this value (for comet, this is 50)
series count = 2 # how many series per charge level in theoretical sequences. !! MUST MATCH YOUR THEOREICAL SEQUENCE SETTINGS !!
ignore weights = true # ignore theoretical sequence weight factors

# If ppm, calculate ppm based on what?
# bins: iteratively from the max mass down to 0
# max: like abs but based on each spectrum's max mass by ppm
# mass: like abs but based on each spectrum's neutral mass by ppm
# min bin width bounds the values calculated by those methods
# For ppm mode = bins, min bin width MUST be non-zero.
# Negative values are interpreted as 0.
ppm mode = max
min bin width = 0.001

# Comet adds "flanking peaks" to the spectrum correction phase
# which greatly increases identifications.
# The default method is to use just half of the two side bins, which is method "exp" with length of 1.
# "none" disables flanking peaks.
# "exp" adds (1/2)^n of each bin with a distance of n from the current bin, stopping when either end
#of the sequence is reached, up to flank length steps.
# "gauss" is like exp but with a N(0, 1) kernel.
flank mode = gauss
flank length = 2

[scoring.hyperscore]
norm type = max # sum = identipy, max = x!tandem, default = max
peak matching tolerance = 120 # mass error tolerance for matching peaks
peak matching unit = ppm # ppm or abs (any non-ppm value assumed to be abs)
match only closest peak = true # whether to consider a match only to the closest peak in the spectrum, or all within range
cutoff = 0.05 # minimum peak intensity after renormalization (see norm type)
match multiplier = 1 # multiply the score value of matching a peak by this factor
disjoint model = false # if true: assumes intensity sum separately from match factorials (x!tandem default). If false: assumes each match factorial is independently responsible for the whole sum intensity
# (false is pepid default)
max best = 1 # how many out of the best matches to keep (must be > 0)
criterion best = matches # (matched) intensity or matches (count): what criterion to use to decide what is "best"
type best = both # take best N what? (best N {charge,series,both}). Charge means y2+ and y3+ compete, but b3+ and y3+ are together.
#Series means y2+ and y3+ are together, but b3+ competes with them.
#Both means y2+, y3+ and b3+ are all competing.
series count = 2 # how many series per charge level in theoretical sequences. !! MUST MATCH YOUR THEOREICAL SEQUENCE SETTINGS !!
ignore weights = true # ignore theoretical sequence weight factors

[output]
# Note that output operates at the db file level, mind the batch size!
max retained candidates = 10
workers = 64
batch size = 16

[rescoring]
#function = pepid_randomforest.rescore
function = pepid_percolator.rescore
suffix = _final # Suffix to use to generate the rescored results filename. Cannot be empty.
batch size = 1180 # Batch size for rescoring, in spectra

[pipeline]
search = true
postsearch = true
output = true
report = true
rescoring = true
rescoring report = true
