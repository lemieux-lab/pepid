[performance]
query nodes = 16 # how many nodes to use for parallel ops (0 = run sequentially): query processing.
post query nodes = 16 # how many nodes for post-processing queries
db nodes = 16 # as above: db processing. db and query nodes run simultaneously.
post db nodes = 16 # how many nodes for post-processing db entries
search nodes = 32 # as above: search processing. Note that search runs after db and query processing are complete.
batch size = 100 # size of chunks to process in parallel, when applicable
python = python # path to python executable to use for multiprocessing
postgresql path = pgsql/ # path to pgsql install location

[data]
output = pepid.csv # where to save the results
queries = queries.mgf # input query mgf
database = db.fasta # input database
tmpdir = ./ # where to put temporary files

[search]
max retained candidates = 100 # only keep these many candidates per query
max peaks = 500 # Maximum peak count in an acceptable spectrum, discarded otherwise
min peaks = 20 # Minimum peak count
variable modifications = M+15.994915 # Comma-separated mod list (default: M(ox))
fixed modifications = C+57.0215 # Comma-separated mod list (default: CAM)
peak matching tolerance = 10 # mass error tolerance for matching peaks
matching unit = ppm # ppm or abs (any non-ppm value assumed to be abs)
candidate filtering tolerance = -100,100 # left and right side tolerance for candidate filtering previous to search
filtering unit = ppm
nterm cleavage = 1.007825
cterm cleavage = 17.002735
max variable modifications = 3

[queries]
# Function run with a batch of queries as input for user extension via scoring.
# (see my_script.predict_length for an example)
user processing function = my_script.predict_length

[scoring]
# Scoring function to use
score function = search.rnhs

[database]
# Digestion rule as a regular expression
#digestion = [RK](?!P) # trypsin: "R or K except when followed by P"
digestion = ([RK](?!P))|((?<=W)K(?=P))|((?<=M)R(?=P))
max missed cleavages = 2
# required digested peptide properties for inclusion below
min length = 7
max length = 40
min mass = 250
max mass = 6000
spectrum function = db.theoretical_spectrum # function to use to generate spectra for candidates
rt function = db.pred_rt # function to use for retention time prediction

[decoys]
generate decoys = true
decoy prefix = DECOY_
decoy method = reverse # possible choices are reverse or shuffle

[logging]
level = info # Valid values are debug, info, warning, error, fatal.

[report]
retain = 1 # How many scores to retain per spectrum for reporting
out = report # output directory for report artifacts

[pipeline]
search = true # Whether to perform search
report = true # Whether to generate a report prior to rescoring
report type = fdr # Whether to report fdp or fdr (target-decoy approach)
rescore = true
rescorer = pepid_percolator.rescore # script to call for rescoring (empty for none)
rescore suffix = _final # Suffix to use to generate the rescored results filename. Cannot be empty.
final report = true # Whether to generate a report after rescoring
final report type = fdr
